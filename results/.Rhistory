# Load Packages
library(ggplot2)
library(dplyr)
library(latex2exp)
library(stats4)
library(ggpubr)
library(mvtnorm)
# function for checking NA
check_na = function(data){
p = ncol(data)
check_na = c()
for(i in 1:p){
check_na[i] = sum(is.na(data[,i]))
}
names(check_na) = colnames(data)
return(check_na)
}
# load data
temp1 = read.csv("/Users/ilgeehong/Desktop/UChicago/2022 Spring/STAT 348/Final/COVID-19_Cases_US.csv")
temp2 = temp1%>%select(-Last_Update, -People_Tested, -People_Hospitalized, -Recovered, -ISO3, -Country_Region, -FIPS, -Lat, -Long_)
# Lat, Long is duplicate
# check na
check_na(temp2)
temp3 = temp2%>%filter(!is.na(temp2$X)) # 57 observations of NA on X, Y, Incident Rate
# check na
check_na(temp3)
temp4 = temp3%>%mutate(Death_Rate = Deaths/Confirmed) # add new column called "Death_Rate"
# check na
check_na(temp4)
temp4[is.na(temp4$Death_Rate),]$Death_Rate <- 0
temp5 = temp4
check_na(temp5)
# confirm the data set
covid = temp5
# function for computing the distance
dist = function(X,Y){
# input: lat, long
# output: Euclidean distance
d1 = outer(X,X,"-")
d2 = outer(Y,Y,"-")
d = sqrt(d1^2 + d2^2)
return(d)
}
# function for computing K(d)
cov_fun = function(lambda, l, X, Y){
# input: lambda, l, lat, long
# output: K(d)
cov = (lambda^2)*exp(-(dist(X,Y)^2)/(2*(l^2)))
return(cov)
}
# function for computing the log-likelihood
GP_log_likelihood = function(lambda, l, sigma, mu, X, Y, y){
# input: lambda, l, sigma, mu, lat, long, y
# output: log-likelihood
n = length(y)
Sigma = cov_fun(lambda, l, X, Y)+(sigma^2)*diag(n)
lh = sum(mvtnorm::dmvnorm(y, mean=rep(mu,n), sigma=Sigma, log=TRUE))
return(lh)
}
# function for computing maximum likelihood estimates
get_mle = function(y, X, Y){
# input: y, lat, long
# output: mle, maximum log-likelihood
res = optim(par = c(1,1,1,1), fn = function(x){GP_log_likelihood(x[1],x[2],x[3],x[4], X, Y, y)}, control=list(fnscale=-1), method = "L-BFGS-B", lower=1e-4)
mle = res$par
loglik = GP_log_likelihood(mle[1], mle[2], mle[3], mle[4], X, Y, y)
return(list(lambda=mle[1], l=mle[2], sigma=mle[3], mu=mle[4], loglik=loglik))
}
# simulation study
set.seed(1)
lambda = 3
l = 1
mu = 3
sigma = 1
n = 1000
X = runif(n,-10,10)
Y = runif(n,-10,10)
y = rmvnorm(1, mean=rep(mu,n), sigma=(cov_fun(lambda,l,X,Y)+(sigma^2)*diag(n)))
mle = get_mle(y, X, Y)
# true log-likelihood
true_loglik = GP_log_likelihood(lambda, l, sigma, mu, X, Y, y)
cat("MLE for lambda: ", mle$lambda, "\nMLE for l: ", mle$l, "\nMLE for sigma: ", mle$sigma, "\nMLE for mu: ", mle$mu, "\nMaximum log-likelihood: ", mle$loglik, "\nTrue log-likelihood: ", true_loglik)
# random subset of 500 counties
set.seed(2022)
ind = sample(1:nrow(covid),500)
covid_new = covid[ind,]
# remove the observations which have 0 incident rate
covid_new = covid_new%>%filter(is.finite(log(covid_new$Incident_Rate)))
# apply the code to the COVID-19 data
covid_mle = get_mle(log(covid_new$Incident_Rate), covid_new$X, covid_new$Y)
cat("MLE for lambda: ", covid_mle$lambda, "\nMLE for l: ", covid_mle$l, "\nMLE for sigma: ", covid_mle$sigma, "\nMLE for mu: ", covid_mle$mu, "\nMaximum log-likelihood: ", covid_mle$loglik)
# function for computing log-likelihood for non-spatial model
GP_log_likelihood_ns = function(sigma, mu, X, Y, y){
# input: sigma, mu, lat, long, y
# output: log-likelihood
n = length(y)
Sigma = (sigma^2)*diag(n)
lh = sum(mvtnorm::dmvnorm(y, mean=rep(mu,n), sigma=Sigma, log=TRUE))
return(lh)
}
# function for computing maximum likelihood estimates
get_mle_ns = function(y, X, Y){
# input: y, lat, long
# output: mle, maximum log-likelihood
res = optim(par = c(1,1), fn = function(x){GP_log_likelihood_ns(x[1], x[2], X, Y, y)}, control=list(fnscale=-1), method = "L-BFGS-B", lower=1e-4)
mle = res$par
loglik = GP_log_likelihood_ns(mle[1], mle[2], X, Y, y)
return(list(lambda=NA, l=NA, sigma=mle[1], mu=mle[2], loglik=loglik))
}
covid_mle_ns = get_mle_ns(log(covid_new$Incident_Rate), covid_new$X, covid_new$Y)
cat("MLE for sigma: ", covid_mle_ns$sigma, "\nMLE for mu: ", covid_mle_ns$mu)
cat("Log-likelihood (spatial model): ", covid_mle$loglik, "\nLog-likelihood (non-spatial model): ", covid_mle_ns$loglik)
n = nrow(covid_new)
sigma = (cov_fun(covid_mle$lambda,covid_mle$l,covid_new$X,covid_new$Y)+(covid_mle$sigma^2)*diag(n))
y = log(covid_new$Incident_Rate)
mu = rep(covid_mle$mu,n)
sig1 = sigma[1,-1]
sig2 = sigma[-1,-1]
mu1 = mu[1]
mu2 = mu[-1]
sig1%*%backsolve(chol(sig2),forwardsolve(t(chol(sig2)))))
sig1%*%backsolve(chol(sig2),forwardsolve(t(chol(sig2))))
n = nrow(covid_new)
sigma = (cov_fun(covid_mle$lambda,covid_mle$l,covid_new$X,covid_new$Y)+(covid_mle$sigma^2)*diag(n))
y = log(covid_new$Incident_Rate)
mu = rep(covid_mle$mu,n)
sig1 = sigma[1,-1]
sig2 = sigma[-1,-1]
mu1 = mu[1]
mu2 = mu[-1]
sig1%*%backsolve(chol(sig2),forwardsolve(t(chol(sig2))))
n = nrow(covid_new)
sigma = (cov_fun(covid_mle$lambda,covid_mle$l,covid_new$X,covid_new$Y)+(covid_mle$sigma^2)*diag(n))
y = log(covid_new$Incident_Rate)
mu = rep(covid_mle$mu,n)
sig1 = sigma[1,-1]
sig2 = sigma[-1,-1]
mu1 = mu[1]
mu2 = mu[-1]
sig1%*%backsolve(chol(sig2),forwardsolve(t(chol(sig2)),y[-i]))
n = nrow(covid_new)
sigma = (cov_fun(covid_mle$lambda,covid_mle$l,covid_new$X,covid_new$Y)+(covid_mle$sigma^2)*diag(n))
y = log(covid_new$Incident_Rate)
mu = rep(covid_mle$mu,n)
sig1 = sigma[1,-1]
sig2 = sigma[-1,-1]
mu1 = mu[1]
mu2 = mu[-1]
sig1%*%backsolve(chol(sig2),forwardsolve(t(chol(sig2)),y[-1]))
sig1%*%inv(sig2)
install.package("matlib")
install.packages("matlib")
install.packages("matlib")
install.packages("matlib")
knitr::opts_chunk$set(echo = TRUE, warning =FALSE, message = FALSE)
knitr::opts_chunk$set(fig.width=4, fig.height=4, fig.align = "center")
# Load Packages
library(ggplot2)
library(dplyr)
library(latex2exp)
library(stats4)
library(ggpubr)
library(mvtnorm)
# function for checking NA
check_na = function(data){
p = ncol(data)
check_na = c()
for(i in 1:p){
check_na[i] = sum(is.na(data[,i]))
}
names(check_na) = colnames(data)
return(check_na)
}
# load data
temp1 = read.csv("/Users/ilgeehong/Desktop/UChicago/2022 Spring/STAT 348/Final/COVID-19_Cases_US.csv")
temp2 = temp1%>%select(-Last_Update, -People_Tested, -People_Hospitalized, -Recovered, -ISO3, -Country_Region, -FIPS, -Lat, -Long_)
# Lat, Long is duplicate
# check na
check_na(temp2)
temp3 = temp2%>%filter(!is.na(temp2$X)) # 57 observations of NA on X, Y, Incident Rate
# check na
check_na(temp3)
temp4 = temp3%>%mutate(Death_Rate = Deaths/Confirmed) # add new column called "Death_Rate"
# check na
check_na(temp4)
temp4[is.na(temp4$Death_Rate),]$Death_Rate <- 0
temp5 = temp4
check_na(temp5)
# confirm the data set
covid = temp5
# function for computing the distance
dist = function(X,Y){
# input: lat, long
# output: Euclidean distance
d1 = outer(X,X,"-")
d2 = outer(Y,Y,"-")
d = sqrt(d1^2 + d2^2)
return(d)
}
# function for computing K(d)
cov_fun = function(lambda, l, X, Y){
# input: lambda, l, lat, long
# output: K(d)
cov = (lambda^2)*exp(-(dist(X,Y)^2)/(2*(l^2)))
return(cov)
}
# function for computing the log-likelihood
GP_log_likelihood = function(lambda, l, sigma, mu, X, Y, y){
# input: lambda, l, sigma, mu, lat, long, y
# output: log-likelihood
n = length(y)
Sigma = cov_fun(lambda, l, X, Y)+(sigma^2)*diag(n)
lh = sum(mvtnorm::dmvnorm(y, mean=rep(mu,n), sigma=Sigma, log=TRUE))
return(lh)
}
# function for computing maximum likelihood estimates
get_mle = function(y, X, Y){
# input: y, lat, long
# output: mle, maximum log-likelihood
res = optim(par = c(1,1,1,1), fn = function(x){GP_log_likelihood(x[1],x[2],x[3],x[4], X, Y, y)}, control=list(fnscale=-1), method = "L-BFGS-B", lower=1e-4)
mle = res$par
loglik = GP_log_likelihood(mle[1], mle[2], mle[3], mle[4], X, Y, y)
return(list(lambda=mle[1], l=mle[2], sigma=mle[3], mu=mle[4], loglik=loglik))
}
# simulation study
set.seed(1)
lambda = 3
l = 1
mu = 3
sigma = 1
n = 1000
X = runif(n,-10,10)
Y = runif(n,-10,10)
y = rmvnorm(1, mean=rep(mu,n), sigma=(cov_fun(lambda,l,X,Y)+(sigma^2)*diag(n)))
mle = get_mle(y, X, Y)
# true log-likelihood
true_loglik = GP_log_likelihood(lambda, l, sigma, mu, X, Y, y)
cat("MLE for lambda: ", mle$lambda, "\nMLE for l: ", mle$l, "\nMLE for sigma: ", mle$sigma, "\nMLE for mu: ", mle$mu, "\nMaximum log-likelihood: ", mle$loglik, "\nTrue log-likelihood: ", true_loglik)
# random subset of 500 counties
set.seed(2022)
ind = sample(1:nrow(covid),500)
covid_new = covid[ind,]
# remove the observations which have 0 incident rate
covid_new = covid_new%>%filter(is.finite(log(covid_new$Incident_Rate)))
# apply the code to the COVID-19 data
covid_mle = get_mle(log(covid_new$Incident_Rate), covid_new$X, covid_new$Y)
cat("MLE for lambda: ", covid_mle$lambda, "\nMLE for l: ", covid_mle$l, "\nMLE for sigma: ", covid_mle$sigma, "\nMLE for mu: ", covid_mle$mu, "\nMaximum log-likelihood: ", covid_mle$loglik)
# function for computing log-likelihood for non-spatial model
GP_log_likelihood_ns = function(sigma, mu, X, Y, y){
# input: sigma, mu, lat, long, y
# output: log-likelihood
n = length(y)
Sigma = (sigma^2)*diag(n)
lh = sum(mvtnorm::dmvnorm(y, mean=rep(mu,n), sigma=Sigma, log=TRUE))
return(lh)
}
# function for computing maximum likelihood estimates
get_mle_ns = function(y, X, Y){
# input: y, lat, long
# output: mle, maximum log-likelihood
res = optim(par = c(1,1), fn = function(x){GP_log_likelihood_ns(x[1], x[2], X, Y, y)}, control=list(fnscale=-1), method = "L-BFGS-B", lower=1e-4)
mle = res$par
loglik = GP_log_likelihood_ns(mle[1], mle[2], X, Y, y)
return(list(lambda=NA, l=NA, sigma=mle[1], mu=mle[2], loglik=loglik))
}
covid_mle_ns = get_mle_ns(log(covid_new$Incident_Rate), covid_new$X, covid_new$Y)
cat("MLE for sigma: ", covid_mle_ns$sigma, "\nMLE for mu: ", covid_mle_ns$mu)
cat("Log-likelihood (spatial model): ", covid_mle$loglik, "\nLog-likelihood (non-spatial model): ", covid_mle_ns$loglik)
# spatially-informed predictor
GP_predictor = function(y, mu, sigma){
# input: y, mu, sigma
# output: conditional mean estimates
n = length(y)
cond_mean = c()
for(i in 1:n){
sig1 = sigma[i,-i]
sig2 = sigma[-i,-i]
mu1 = mu[i]
mu2 = mu[-i]
cond_mean[i] = mu1 + sig1%*%backsolve(chol(sig2),forwardsolve(t(chol(sig2)),(y[-i]-mu2)))
}
return(cond_mean)
}
# naive predictor
naive_predictor = function(y){
# input: y
# output: leave-one-out sample mean estimates
n = length(y)
naive = c()
for(i in 1:n){
naive[i] = mean(y[-i])
}
return(naive)
}
# setting
n = nrow(covid_new)
sigma = (cov_fun(covid_mle$lambda,covid_mle$l,covid_new$X,covid_new$Y)+(covid_mle$sigma^2)*diag(n))
# get predicted values
SIP = GP_predictor(log(covid_new$Incident_Rate),rep(covid_mle$mu,n),sigma)
NAI = naive_predictor(log(covid_new$Incident_Rate))
# plotting
plot(log(covid_new$Incident_Rate), SIP, col = 'blue', xlab = TeX(r"($Y_i$)"), ylab = "predicted value", xlim=c(0,10), ylim=c(0,10))
points(log(covid_new$Incident_Rate), NAI, col = 'red')
abline(a=0,b=1)
legend('bottomright', pch = 1, legend=c('spatially informed predictor','naive predictor'), col = c("blue","red"))
install.packages("matlib")
install.packages("matlib")
library(matlib)
# Load Packages
library(ggplot2)
library(dplyr)
library(latex2exp)
library(stats4)
library(ggpubr)
library(mvtnorm)
knitr::opts_chunk$set(echo = TRUE, warning =FALSE, message = FALSE)
knitr::opts_chunk$set(fig.width=4, fig.height=4, fig.align = "center")
# Load Packages
library(ggplot2)
library(dplyr)
library(latex2exp)
library(stats4)
library(ggpubr)
library(mvtnorm)
# function for checking NA
check_na = function(data){
p = ncol(data)
check_na = c()
for(i in 1:p){
check_na[i] = sum(is.na(data[,i]))
}
names(check_na) = colnames(data)
return(check_na)
}
# load data
temp1 = read.csv("/Users/ilgeehong/Desktop/UChicago/2022 Spring/STAT 348/Final/COVID-19_Cases_US.csv")
temp2 = temp1%>%select(-Last_Update, -People_Tested, -People_Hospitalized, -Recovered, -ISO3, -Country_Region, -FIPS, -Lat, -Long_)
# Lat, Long is duplicate
# check na
check_na(temp2)
temp3 = temp2%>%filter(!is.na(temp2$X)) # 57 observations of NA on X, Y, Incident Rate
# check na
check_na(temp3)
temp4 = temp3%>%mutate(Death_Rate = Deaths/Confirmed) # add new column called "Death_Rate"
# check na
check_na(temp4)
temp4[is.na(temp4$Death_Rate),]$Death_Rate <- 0
temp5 = temp4
check_na(temp5)
# confirm the data set
covid = temp5
# function for computing the distance
dist = function(X,Y){
# input: lat, long
# output: Euclidean distance
d1 = outer(X,X,"-")
d2 = outer(Y,Y,"-")
d = sqrt(d1^2 + d2^2)
return(d)
}
# function for computing K(d)
cov_fun = function(lambda, l, X, Y){
# input: lambda, l, lat, long
# output: K(d)
cov = (lambda^2)*exp(-(dist(X,Y)^2)/(2*(l^2)))
return(cov)
}
# function for computing the log-likelihood
GP_log_likelihood = function(lambda, l, sigma, mu, X, Y, y){
# input: lambda, l, sigma, mu, lat, long, y
# output: log-likelihood
n = length(y)
Sigma = cov_fun(lambda, l, X, Y)+(sigma^2)*diag(n)
lh = sum(mvtnorm::dmvnorm(y, mean=rep(mu,n), sigma=Sigma, log=TRUE))
return(lh)
}
# function for computing maximum likelihood estimates
get_mle = function(y, X, Y){
# input: y, lat, long
# output: mle, maximum log-likelihood
res = optim(par = c(1,1,1,1), fn = function(x){GP_log_likelihood(x[1],x[2],x[3],x[4], X, Y, y)}, control=list(fnscale=-1), method = "L-BFGS-B", lower=1e-4)
mle = res$par
loglik = GP_log_likelihood(mle[1], mle[2], mle[3], mle[4], X, Y, y)
return(list(lambda=mle[1], l=mle[2], sigma=mle[3], mu=mle[4], loglik=loglik))
}
# simulation study
set.seed(1)
lambda = 3
l = 1
mu = 3
sigma = 1
n = 1000
X = runif(n,-10,10)
Y = runif(n,-10,10)
y = rmvnorm(1, mean=rep(mu,n), sigma=(cov_fun(lambda,l,X,Y)+(sigma^2)*diag(n)))
mle = get_mle(y, X, Y)
# true log-likelihood
true_loglik = GP_log_likelihood(lambda, l, sigma, mu, X, Y, y)
cat("MLE for lambda: ", mle$lambda, "\nMLE for l: ", mle$l, "\nMLE for sigma: ", mle$sigma, "\nMLE for mu: ", mle$mu, "\nMaximum log-likelihood: ", mle$loglik, "\nTrue log-likelihood: ", true_loglik)
# random subset of 500 counties
set.seed(2022)
ind = sample(1:nrow(covid),500)
covid_new = covid[ind,]
# remove the observations which have 0 incident rate
covid_new = covid_new%>%filter(is.finite(log(covid_new$Incident_Rate)))
# apply the code to the COVID-19 data
covid_mle = get_mle(log(covid_new$Incident_Rate), covid_new$X, covid_new$Y)
cat("MLE for lambda: ", covid_mle$lambda, "\nMLE for l: ", covid_mle$l, "\nMLE for sigma: ", covid_mle$sigma, "\nMLE for mu: ", covid_mle$mu, "\nMaximum log-likelihood: ", covid_mle$loglik)
# function for computing log-likelihood for non-spatial model
GP_log_likelihood_ns = function(sigma, mu, X, Y, y){
# input: sigma, mu, lat, long, y
# output: log-likelihood
n = length(y)
Sigma = (sigma^2)*diag(n)
lh = sum(mvtnorm::dmvnorm(y, mean=rep(mu,n), sigma=Sigma, log=TRUE))
return(lh)
}
# function for computing maximum likelihood estimates
get_mle_ns = function(y, X, Y){
# input: y, lat, long
# output: mle, maximum log-likelihood
res = optim(par = c(1,1), fn = function(x){GP_log_likelihood_ns(x[1], x[2], X, Y, y)}, control=list(fnscale=-1), method = "L-BFGS-B", lower=1e-4)
mle = res$par
loglik = GP_log_likelihood_ns(mle[1], mle[2], X, Y, y)
return(list(lambda=NA, l=NA, sigma=mle[1], mu=mle[2], loglik=loglik))
}
covid_mle_ns = get_mle_ns(log(covid_new$Incident_Rate), covid_new$X, covid_new$Y)
cat("MLE for sigma: ", covid_mle_ns$sigma, "\nMLE for mu: ", covid_mle_ns$mu)
cat("Log-likelihood (spatial model): ", covid_mle$loglik, "\nLog-likelihood (non-spatial model): ", covid_mle_ns$loglik)
# spatially-informed predictor
GP_predictor = function(y, mu, sigma){
# input: y, mu, sigma
# output: conditional mean estimates
n = length(y)
cond_mean = c()
for(i in 1:n){
sig1 = sigma[i,-i]
sig2 = sigma[-i,-i]
mu1 = mu[i]
mu2 = mu[-i]
cond_mean[i] = mu1 + sig1%*%backsolve(chol(sig2),forwardsolve(t(chol(sig2)),(y[-i]-mu2)))
}
return(cond_mean)
}
# naive predictor
naive_predictor = function(y){
# input: y
# output: leave-one-out sample mean estimates
n = length(y)
naive = c()
for(i in 1:n){
naive[i] = mean(y[-i])
}
return(naive)
}
# setting
n = nrow(covid_new)
sigma = (cov_fun(covid_mle$lambda,covid_mle$l,covid_new$X,covid_new$Y)+(covid_mle$sigma^2)*diag(n))
# get predicted values
SIP = GP_predictor(log(covid_new$Incident_Rate),rep(covid_mle$mu,n),sigma)
NAI = naive_predictor(log(covid_new$Incident_Rate))
# plotting
plot(log(covid_new$Incident_Rate), SIP, col = 'blue', xlab = TeX(r"($Y_i$)"), ylab = "predicted value", xlim=c(0,10), ylim=c(0,10))
points(log(covid_new$Incident_Rate), NAI, col = 'red')
abline(a=0,b=1)
legend('bottomright', pch = 1, legend=c('spatially informed predictor','naive predictor'), col = c("blue","red"))
# function for computing MSE
MSE = function(x,y){
return(sum((x-y)^2)/length(x))
}
cat("MSE with spatially informed predictor", MSE(log(covid_new$Incident_Rate), SIP),"\nMSE with naive predictor",MSE(log(covid_new$Incident_Rate), NAI))
solve(chol(sig2),forwardsolve(t(chol(sig2)),sig1))
n = nrow(covid_new)
sigma = (cov_fun(covid_mle$lambda,covid_mle$l,covid_new$X,covid_new$Y)+(covid_mle$sigma^2)*diag(n))
y = log(covid_new$Incident_Rate)
mu = rep(covid_mle$mu,n)
sig1 = sigma[1,-1]
sig2 = sigma[-1,-1]
mu1 = mu[1]
mu2 = mu[-1]
solve(chol(sig2),forwardsolve(t(chol(sig2)),sig1))
n = nrow(covid_new)
sigma = (cov_fun(covid_mle$lambda,covid_mle$l,covid_new$X,covid_new$Y)+(covid_mle$sigma^2)*diag(n))
y = log(covid_new$Incident_Rate)
mu = rep(covid_mle$mu,n)
sig1 = sigma[1,-1]
sig2 = sigma[-1,-1]
mu1 = mu[1]
mu2 = mu[-1]
x = solve(chol(sig2),forwardsolve(t(chol(sig2)),sig1))
t(x)
dim(t(x))
sum(t(x)==0)
sum(t(x))
sum(abs(t(x)))
mean(as.numeric(substr(semcon_citeseer$accuracy,8,13)))
sd(as.numeric(substr(semcon_citeseer$accuracy,8,13)))
setwd("/Users/ilgeehong/Desktop/SemGCon/results")
semcon_citeseer = read.csv("SemiGCon_node_classification_random_CiteSeer.csv")
mean(as.numeric(substr(semcon_citeseer$accuracy,8,13)))
sd(as.numeric(substr(semcon_citeseer$accuracy,8,13)))
semcon_citeseer2 = read.csv("SemiGCon_node_classification_random_CiteSeer.csv")
semcon_citeseer1 = read.csv("SemiGCon_node_classification_CiteSeer.csv")
semcon_citeseer2 = read.csv("SemiGCon_node_classification_random_CiteSeer.csv")
semcon_citeseer1 = read.csv("SemGCon_node_classification_CiteSeer.csv")
mean(as.numeric(substr(semcon_citeseer2$accuracy,8,13)))
sd(as.numeric(substr(semcon_citeseer2$accuracy,8,13)))
mean(as.numeric(substr(semcon_citeseer1$accuracy,8,13)))
sd(as.numeric(substr(semcon_citeseer1$accuracy,8,13)))
semcon_citeseer1 = read.csv("SemCon_node_classification_CiteSeer.csv")
mean(as.numeric(substr(semcon_citeseer1$accuracy,8,13)))
sd(as.numeric(substr(semcon_citeseer1$accuracy,8,13)))
